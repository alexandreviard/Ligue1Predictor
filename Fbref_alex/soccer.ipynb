{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from fonctions_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SOCCER_201223_18h.csv\")\n",
    "mapping_equipe2 = {\n",
    "    'Nimes': 'Nîmes',\n",
    "    'Paris S-G': 'Paris Saint Germain',\n",
    "    'Saint Etienne': 'Saint-Étienne'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess(df, mapping_equipe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n",
      "/home/onyxia/work/fonctions_preprocess.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Moyenne_{col}_Lag'] = df.groupby(['Saison', 'equipe'])[col].transform(lambda x: x.shift(1).expanding().mean())\n"
     ]
    }
   ],
   "source": [
    "df = preparation_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Points_Cum_Lag1', 'GD_Cum_Lag1', 'GF_Cum_Lag1', 'GA_Cum_Lag1'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/onyxia/work/soccer.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://user-alexandreviard-610998-0.user.lab.sspcloud.fr/home/onyxia/work/soccer.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m variables_moyenne \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mfilter(like\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMoyenne_\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://user-alexandreviard-610998-0.user.lab.sspcloud.fr/home/onyxia/work/soccer.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m variables_moyenne \u001b[39m=\u001b[39m variables_moyenne\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m---> <a href='vscode-notebook-cell://user-alexandreviard-610998-0.user.lab.sspcloud.fr/home/onyxia/work/soccer.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m test_df \u001b[39m=\u001b[39m test_df[[\u001b[39m\"\u001b[39;49m\u001b[39mDateTime\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mComp\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mSaison\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mRound\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mFormation\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mVenue\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mequipe\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mResult\u001b[39;49m\u001b[39m\"\u001b[39;49m,\t\u001b[39m\"\u001b[39;49m\u001b[39mGF\u001b[39;49m\u001b[39m\"\u001b[39;49m,\t\u001b[39m\"\u001b[39;49m\u001b[39mGA\u001b[39;49m\u001b[39m\"\u001b[39;49m,\t\u001b[39m\"\u001b[39;49m\u001b[39mOpponent\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mGD\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPoints\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPoints_Cum\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mGD_Cum\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mClassement\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mGF_Cum\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mGA_Cum\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mCumulativeLosses\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mPast_Matches\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mCumulativeWins\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mCumulativeDraws\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPoints_Cum_Lag1\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mGD_Cum_Lag1\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mGF_Cum_Lag1\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mGA_Cum_Lag1\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mFormation\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m+\u001b[39;49mvariables_moyenne]\n\u001b[1;32m     <a href='vscode-notebook-cell://user-alexandreviard-610998-0.user.lab.sspcloud.fr/home/onyxia/work/soccer.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Supprimez les lignes avec des valeurs NaN dans l'ensemble de la base de données\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://user-alexandreviard-610998-0.user.lab.sspcloud.fr/home/onyxia/work/soccer.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m test_df\u001b[39m.\u001b[39mdropna(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/core/indexes/base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6116\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6118\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/core/indexes/base.py:6178\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6177\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6178\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Points_Cum_Lag1', 'GD_Cum_Lag1', 'GF_Cum_Lag1', 'GA_Cum_Lag1'] not in index\""
     ]
    }
   ],
   "source": [
    "test_df = df.copy()\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Charger votre DataFrame TEST\n",
    "# Assurez-vous que les variables \"Venue\" et \"Opponent\" sont des objets (str) pour l'encodage en variables factices\n",
    "# Par exemple, si votre DataFrame est appelé test_df :\n",
    "# test_df['Venue'] = test_df['Venue'].astype(str)\n",
    "# test_df['Opponent'] = test_df['Opponent'].astype(str)\n",
    "\n",
    "# Convertissez la colonne \"DateTime\" en format de date\n",
    "# Convertissez la colonne \"DateTime\" en format de date\n",
    "test_df['DateTime'] = pd.to_datetime(test_df['DateTime'])\n",
    "\n",
    "variables_moyenne = df.filter(like='Moyenne_', axis=1)\n",
    "variables_moyenne = variables_moyenne.columns.tolist()\n",
    "\n",
    "\n",
    "test_df = test_df[[\"DateTime\", \"Comp\", \"Saison\", \"Round\", \"Formation\", \"Venue\", \"equipe\",\"Result\",\t\"GF\",\t\"GA\",\t\"Opponent\", \"GD\", \"Points\", \"Points_Cum\", \"GD_Cum\", \"Classement\", \"GF_Cum\", \"GA_Cum\",\"CumulativeLosses\",\"Past_Matches\", \"CumulativeWins\", \"CumulativeDraws\", \"Points_Cum_Lag1\", \"GD_Cum_Lag1\", \"GF_Cum_Lag1\", \"GA_Cum_Lag1\", \"Formation\"]+variables_moyenne]\n",
    "# Supprimez les lignes avec des valeurs NaN dans l'ensemble de la base de données\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "# Filtrer les matchs avec \"Round\" > 5\n",
    "test_df = test_df[test_df['Round'] > 0]\n",
    "\n",
    "# Fixez la date de coupure (cutoff) en juillet 2023\n",
    "cutoff_date = pd.to_datetime('2021-12-12')\n",
    "\n",
    "\n",
    "# Sélectionner les variables numériques\n",
    "num_features = [\"Past_Matches\", \"Moyenne_Standard_SoT%\"] +variables_moyenne\n",
    "#\"CPoints_Lag1\", \"CGD_Lag1\", \"Classement_Lag1\"\n",
    "#, \"CumulativeWins\", \"CumulativeDraws\",\"CumulativeLosses\",\n",
    "\n",
    "#\"Moyenne_Total_Cmp%\", \"Moyenne_Poss_x\",'Moyenne_Touches_Def_Pen',  'Moyenne_Touches_Def_3rd']\n",
    "\n",
    "# Sélectionner les variables catégorielles\n",
    "cat_features = [\"Venue\", \"Opponent\", \"Formation\"]\n",
    "\n",
    "\n",
    "# Utilisez pd.get_dummies pour encoder les variables catégorielles en variables factices\n",
    "encoded_cat_features = pd.get_dummies(test_df[cat_features])\n",
    "\n",
    "# Sélectionnez les variables d'entraînement et de test en combinant les numériques et les factices\n",
    "X = pd.concat([test_df[num_features], encoded_cat_features], axis=1)\n",
    "y = test_df['Result']\n",
    "\n",
    "# Séparez les données en ensembles d'entraînement et de test en utilisant la date de coupure\n",
    "X_train = X[test_df['DateTime'] <= cutoff_date]\n",
    "y_train = y[test_df['DateTime'] <= cutoff_date]\n",
    "X_test = X[test_df['DateTime'] > cutoff_date]\n",
    "y_test = y[test_df['DateTime'] > cutoff_date]\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Créez un modèle Random Forest avec les meilleurs paramètres trouvés\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_features=10, \n",
    "    max_depth=10, \n",
    "    criterion='entropy',\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Entraînez le modèle sur l'ensemble d'entraînement équilibré\n",
    "rf_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Faites des prédictions sur l'ensemble de test\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Évaluez le modèle\n",
    "accuracy_selected = accuracy_score(y_test, y_pred)\n",
    "classification_report_result_selected = classification_report(y_test, y_pred)\n",
    "\n",
    "# Affichez les résultats\n",
    "print(f\"\\nAccuracy with Selected Features: {accuracy_selected:.4f}\")\n",
    "print(\"Classification Report with Selected Features:\\n\", classification_report_result_selected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
